package main

import (
	"context"
	"encoding/json"
	"io/ioutil"
	"os"
	"path/filepath"
	"runtime"
	"time"

	"github.com/alecthomas/kingpin"
	foundation "github.com/estafette/estafette-foundation"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/rs/zerolog/log"
	appsv1 "k8s.io/api/apps/v1"
	batchv1 "k8s.io/api/batch/v1"
	batchv1beta1 "k8s.io/api/batch/v1beta1"
	v1 "k8s.io/api/core/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	k8sruntime "k8s.io/apimachinery/pkg/util/runtime"
	"k8s.io/client-go/informers"
	"k8s.io/client-go/kubernetes"
	"k8s.io/client-go/rest"
	"k8s.io/client-go/tools/cache"
)

var (
	appgroup  string
	app       string
	version   string
	branch    string
	revision  string
	buildDate string
	goVersion = runtime.Version()
)

var (
	stateFileDirectory     = kingpin.Flag("state-file-directory", "Directory the state file is mounted to.").Default("/state").Envar("STATE_FILE_DIRECTORY").String()
	stateFileName          = kingpin.Flag("state-file-name", "Name of the state file.").Default("state.json").Envar("STATE_FILE_NAME").String()
	stateFileConfigmapName = kingpin.Flag("state-file-configmap-name", "Name of the configmap storing the state file.").Envar("STATE_FILE_CONFIGMAP_NAME").String()
	releaseName            = kingpin.Flag("release-name", "Name of Helm release (set as label on prometheus metrics).").Envar("RELEASE_NAME").Required().String()

	// define prometheus metrics
	detectedVulnerabilities = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "estafette_vulnerability_scanner_detected_vulnerabilities",
			Help: "Vulnerabilities found in scanned images",
		},
		[]string{"release", "image", "severity"},
	)

	scannedImagesTotals = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "estafette_vulnerability_scanner_scanned_images_total",
			Help: "Number of scanned images",
		},
		[]string{"release", "status"},
	)

	updatedDatabaseTotals = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "estafette_vulnerability_scanner_updated_database_total",
			Help: "Number of database updates",
		},
		[]string{"release", "status"},
	)
)

func init() {
	prometheus.MustRegister(detectedVulnerabilities)
	prometheus.MustRegister(scannedImagesTotals)
	prometheus.MustRegister(updatedDatabaseTotals)
}

func main() {

	// parse command line parameters
	kingpin.Parse()

	// init log format from envvar ESTAFETTE_LOG_FORMAT
	foundation.InitLoggingFromEnv(foundation.NewApplicationInfo(appgroup, app, version, branch, revision, buildDate))

	// init /liveness endpoint
	foundation.InitLiveness()

	// create context to cancel commands on sigterm
	ctx := foundation.InitCancellationContext(context.Background())

	// creates the in-cluster config
	kubeClientConfig, err := rest.InClusterConfig()
	if err != nil {
		log.Fatal().Err(err).Msg("Failed getting in-cluster kubernetes config")
	}
	// creates the kubernetes clientset
	kubeClientset, err := kubernetes.NewForConfig(kubeClientConfig)
	if err != nil {
		log.Fatal().Err(err).Msg("Failed creating kubernetes clientset")
	}

	// create the shared informer factory and use the client to connect to Kubernetes API
	factory := informers.NewSharedInformerFactory(kubeClientset, 0)

	// create a channel to stop the shared informers gracefully
	stopper := make(chan struct{})
	defer close(stopper)

	// handle kubernetes API crashes
	defer k8sruntime.HandleCrash()

	// create vulnerability scanner
	scanner := NewScanner(ctx)

	// define channel used to gracefully shutdown the application
	gracefulShutdown, _ := foundation.InitGracefulShutdownHandling()

	// read state from file
	log.Info().Msgf("Reading state from state file...")
	vulnerabilityReportState, err := readStateFromStateFile()
	if err != nil {
		log.Error().Err(err).Msg("Failed reading state from state file, resetting state...")
		vulnerabilityReportState = map[string]map[string]float64{}
	} else {
		log.Info().Msgf("Read state for %v images", len(vulnerabilityReportState))
	}

	// expose metrics from previous run
	exposeVulnerabilitiesMetrics(detectedVulnerabilities, vulnerabilityReportState)

	// start prometheus
	foundation.InitMetrics()

	go func(ctx context.Context, vulnerabilityReportState map[string]map[string]float64) {
		// loop indefinitely
		for {

			images, err := getReferencedImages(ctx, kubeClientset)

			if err != nil {
				log.Error().Err(err).Msg("Failed retrieving all referenced container images")

				// sleep random time around 3 minutes
				sleepTime := foundation.ApplyJitter(180)
				log.Info().Msgf("Sleeping for %v seconds...", sleepTime)
				time.Sleep(time.Duration(sleepTime) * time.Second)

				// skip remaining steps
				continue
			}

			// remove unused images from state
			imagesBeforePurge := len(vulnerabilityReportState)
			purgeObsoleteState(vulnerabilityReportState, images)
			log.Info().Msgf("Purged unused images from state. Before: %v images. After: %v images", imagesBeforePurge, len(vulnerabilityReportState))

			// scan all images
			scanImages(scanner, vulnerabilityReportState, images, detectedVulnerabilities, scannedImagesTotals, updatedDatabaseTotals, true)
			log.Info().Msgf("Has state for %v images after scanning", len(vulnerabilityReportState))

			log.Info().Msgf("Writing state to configmap...")
			err = writeStateToConfigmap(ctx, kubeClientset, vulnerabilityReportState)
			if err != nil {
				log.Fatal().Err(err).Msg("Failed writing state to configmap")
			}

			// sleep random time around 3 minutes (making sure it's less than the 5 minutes staleness limit for prometheus metrics)
			sleepTime := foundation.ApplyJitter(180)
			log.Info().Msgf("Sleeping for %v seconds...", sleepTime)
			time.Sleep(time.Duration(sleepTime) * time.Second)
		}
	}(ctx, vulnerabilityReportState)

	// watch pods for all namespaces to quickly detect any new images
	podsInformer := factory.Core().V1().Pods().Informer()

	podsInformer.AddEventHandler(cache.ResourceEventHandlerFuncs{
		AddFunc: func(obj interface{}) {
			pod, ok := obj.(*v1.Pod)
			if !ok {
				log.Warn().Msg("Watcher for pods returns event object of incorrect type")
				return
			}

			scanAddedPod(scanner, vulnerabilityReportState, pod, detectedVulnerabilities, scannedImagesTotals, updatedDatabaseTotals)
		},
	})

	go podsInformer.Run(stopper)

	signalReceived := <-gracefulShutdown
	log.Info().Msgf("Received signal %v. Shutting down...", signalReceived)
}

func scanAddedPod(scanner Scanner, vulnerabilityReportState map[string]map[string]float64, pod *v1.Pod, detectedVulnerabilities *prometheus.GaugeVec, scannedImagesTotals, updatedDatabaseTotals *prometheus.CounterVec) {

	log.Info().Msgf("Pod %v was added, checking for new images...", pod.Name)

	// get images for added pod
	images := getImagesForPodSpec(pod.Spec)

	// check if any of the images are new to the cluster
	newImages := []string{}
	for _, image := range images {
		if _, ok := vulnerabilityReportState[image]; !ok {
			newImages = append(newImages, image)
		}
	}

	if len(newImages) == 0 {
		return
	}

	log.Info().Msgf("Found %v new images in added pod %v, scanning them for vulnerabilities...", len(newImages), pod.Name)

	// scan the new images
	scanImages(scanner, vulnerabilityReportState, newImages, detectedVulnerabilities, scannedImagesTotals, updatedDatabaseTotals, false)
}

func getReferencedImages(ctx context.Context, kubeClientset *kubernetes.Clientset) (images []string, err error) {
	// pod images
	podList, err := kubeClientset.CoreV1().Pods("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForPods(podList.Items)...)

	// deployment images
	deploymentList, err := kubeClientset.AppsV1().Deployments("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForDeployments(deploymentList.Items)...)

	// daemonset images
	daemonsetList, err := kubeClientset.AppsV1().DaemonSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForDaemonSets(daemonsetList.Items)...)

	// statefulset images
	statefulsetList, err := kubeClientset.AppsV1().StatefulSets("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForStatefulSets(statefulsetList.Items)...)

	// job images
	jobList, err := kubeClientset.BatchV1().Jobs("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForJobs(jobList.Items)...)

	// cronjob images
	cronjobList, err := kubeClientset.BatchV1beta1().CronJobs("").List(ctx, metav1.ListOptions{})
	if err != nil {
		return
	}
	images = append(images, getImagesForCronJobs(cronjobList.Items)...)

	// dedupe images
	images = dedupeImages(images)

	return images, nil
}

func purgeObsoleteState(vulnerabilityReportState map[string]map[string]float64, images []string) {

	for image := range vulnerabilityReportState {
		if !foundation.StringArrayContains(images, image) {
			delete(vulnerabilityReportState, image)
		}
	}
}

func scanImages(scanner Scanner, vulnerabilityReportState map[string]map[string]float64, images []string, detectedVulnerabilities *prometheus.GaugeVec, scannedImagesTotals, updatedDatabaseTotals *prometheus.CounterVec, refreshDatabase bool) {

	_, noTrivyDbSync := os.LookupEnv("NO_DBSYNC_VIA_TRIVY")

	if refreshDatabase && !noTrivyDbSync {
		// update vulnerability db
		log.Info().Msg("Updating trivy database...")
		err := scanner.UpdateDatabase()
		dbUpdateStatus := "succeeded"
		if err != nil {
			log.Error().Err(err).Msgf("Failed to update trivy database")
			dbUpdateStatus = "failed"
		}
		if updatedDatabaseTotals != nil {
			updatedDatabaseTotals.With(prometheus.Labels{"release": *releaseName, "status": dbUpdateStatus}).Inc()
		}
	}

	for _, image := range images {
		// scan each image
		log.Info().Msgf("Scanning container image %v for vulnerabilities...", image)
		vulnerabilityReports, err := scanner.ScanImage(image)

		// store state if no error has happened or if the key doesn't exist in the map yet
		if _, ok := vulnerabilityReportState[image]; !ok || err == nil {
			vulnerabilityReportState[image] = groupReportPerLevel(vulnerabilityReports)
		}

		scanStatus := "succeeded"
		if err != nil {
			log.Error().Err(err).Msgf("Scanning image %v failed", image)
			scanStatus = "failed"
		}
		if scannedImagesTotals != nil {
			scannedImagesTotals.With(prometheus.Labels{"release": *releaseName, "status": scanStatus}).Inc()
		}

		exposeVulnerabilitiesMetrics(detectedVulnerabilities, vulnerabilityReportState)

		if len(vulnerabilityReports) > 0 {
			log.Warn().Msgf("Image %v has %v vulnerabilities!", image, len(vulnerabilityReports[0].Vulnerabilities))
		}
	}
}

func exposeVulnerabilitiesMetrics(detectedVulnerabilities *prometheus.GaugeVec, vulnerabilityReportState map[string]map[string]float64) {
	// set # of vulnerabilities in prometheus metric
	if detectedVulnerabilities != nil {

		// reset first so no stale images or vulnerabilities are reported
		detectedVulnerabilities.Reset()

		// loop all reports and expose them as metrics in order to keep them fresh (prometheus metrics turn stale after 5 minutes)
		for im, groupedReport := range vulnerabilityReportState {
			if len(groupedReport) > 0 {
				for severity, v := range groupedReport {
					detectedVulnerabilities.With(prometheus.Labels{"release": *releaseName, "image": im, "severity": severity}).Set(v)
				}
			} else {
				detectedVulnerabilities.With(prometheus.Labels{"release": *releaseName, "image": im, "severity": ""}).Set(float64(0))
			}
		}
	}
}

func getImagesForPodSpec(podspec v1.PodSpec) (images []string) {

	// loop InitContainers and collect images
	if podspec.InitContainers != nil {
		for _, c := range podspec.InitContainers {
			image := c.Image
			images = append(images, image)
		}
	}

	// loop Containers and collect images
	if podspec.Containers != nil {
		for _, c := range podspec.Containers {
			image := c.Image
			images = append(images, image)
		}
	}

	return
}

func getImagesForPods(pods []v1.Pod) (images []string) {

	for _, p := range pods {
		images = append(images, getImagesForPodSpec(p.Spec)...)
	}

	return
}

func getImagesForDeployments(deployments []appsv1.Deployment) (images []string) {

	for _, d := range deployments {
		images = append(images, getImagesForPodSpec(d.Spec.Template.Spec)...)
	}

	return
}

func getImagesForDaemonSets(daemonsets []appsv1.DaemonSet) (images []string) {

	for _, d := range daemonsets {
		images = append(images, getImagesForPodSpec(d.Spec.Template.Spec)...)
	}

	return
}

func getImagesForStatefulSets(statefulsets []appsv1.StatefulSet) (images []string) {

	for _, s := range statefulsets {
		images = append(images, getImagesForPodSpec(s.Spec.Template.Spec)...)
	}

	return
}

func getImagesForJobs(jobs []batchv1.Job) (images []string) {

	for _, j := range jobs {
		images = append(images, getImagesForPodSpec(j.Spec.Template.Spec)...)
	}

	return
}

func getImagesForCronJobs(cronjobs []batchv1beta1.CronJob) (images []string) {

	for _, c := range cronjobs {
		images = append(images, getImagesForPodSpec(c.Spec.JobTemplate.Spec.Template.Spec)...)
	}

	return
}

func dedupeImages(images []string) (dedupedImages []string) {

	for _, image := range images {
		if image != "" && !foundation.StringArrayContains(dedupedImages, image) {
			dedupedImages = append(dedupedImages, image)
		}
	}

	return
}

func groupReportPerLevel(vulnerabilityReports []VulnerabilityReport) (groupedReport map[string]float64) {

	groupedReport = map[string]float64{}

	for _, r := range vulnerabilityReports {
		for _, v := range r.Vulnerabilities {

			// ignore vulnerabilities without a fix
			if v.FixedVersion == "" {
				continue
			}

			if val, ok := groupedReport[v.Severity]; ok {
				groupedReport[v.Severity] = val + 1
			} else {
				groupedReport[v.Severity] = 1
			}
		}
	}

	return
}

func readStateFromStateFile() (map[string]map[string]float64, error) {

	vulnerabilityReportState := map[string]map[string]float64{}

	stateFilePath := filepath.Join(*stateFileDirectory, *stateFileName)

	// check if state file exists in configmap
	if _, err := os.Stat(stateFilePath); !os.IsNotExist(err) {

		log.Info().Msgf("File %v exists, reading contents...", stateFilePath)

		// read state file
		data, err := ioutil.ReadFile(stateFilePath)
		if err != nil {
			return vulnerabilityReportState, err
		}

		log.Info().Msgf("Unmarshalling file %v contents...", stateFilePath)

		// unmarshal state file
		if err := json.Unmarshal(data, &vulnerabilityReportState); err != nil {
			return vulnerabilityReportState, err
		}
	}

	return vulnerabilityReportState, nil
}

func writeStateToConfigmap(ctx context.Context, kubeClientset *kubernetes.Clientset, vulnerabilityReportState map[string]map[string]float64) error {

	namespace := getCurrentNamespace()

	// retrieve configmap
	configMap, err := kubeClientset.CoreV1().ConfigMaps(namespace).Get(ctx, *stateFileConfigmapName, metav1.GetOptions{})
	if err != nil {
		return err
	}

	// marshal state to json
	stateData, err := json.Marshal(vulnerabilityReportState)

	if configMap.Data == nil {
		configMap.Data = make(map[string]string)
	}

	configMap.Data[*stateFileName] = string(stateData)

	// update configmap to have state available when the application runs the next time and for other applications
	_, err = kubeClientset.CoreV1().ConfigMaps(namespace).Update(ctx, configMap, metav1.UpdateOptions{})
	if err != nil {
		return err
	}

	log.Info().Msgf("Stored state in configmap %v...", *stateFileConfigmapName)
	return nil
}

func getCurrentNamespace() string {
	namespace, err := ioutil.ReadFile("/var/run/secrets/kubernetes.io/serviceaccount/namespace")
	if err != nil {
		log.Fatal().Err(err).Msg("Failed reading namespace")
	}

	return string(namespace)
}
